{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#Andrea Burns, Machine Learning Project\n",
    "import os, sys, csv\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def term_frequency_mat(codebook_lengh, wordids, wordcnts):\n",
    "    term_freq = []\n",
    "    for counter, (ids, cnts) in enumerate(zip(wordids, wordcnts)):\n",
    "        vec = np.array([0] * codebook_lengh)\n",
    "        for i, cnt in zip(ids, cnts):\n",
    "            vec[i] = cnt\n",
    "        term_freq.append(vec)\n",
    "        \n",
    "    feature_space = np.vstack(term_freq)\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_term_frequency():\n",
    "\n",
    "    # ****************************************************************************************************\n",
    "    # load word counts\n",
    "    # ****************************************************************************************************\n",
    "    directory = './'\n",
    "\n",
    "    with open(\"codebook_data.p\", 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "        \n",
    "    code_book = loaded_data[0]\n",
    "    graphlets = loaded_data[1]\n",
    "    codebook_lengh = len(code_book)\n",
    "\n",
    "    uuids, wordids, wordcts = [], [], []\n",
    "    video_uuids, true_labels = [], []\n",
    "    num_of_vids = 493\n",
    "    \n",
    "    for task in range(1, num_of_vids):\n",
    "        file = open(\"vid\" + str(task) + \".p\",'rb')\n",
    "        (uuid, label, ids, histogram) = pickle.load(file, encoding='latin1')\n",
    "        wordids.append(ids)\n",
    "        wordcts.append(histogram)\n",
    "        video_uuids.append(uuid)\n",
    "        true_labels.append(label)\n",
    "    \n",
    "    online_data = wordids, wordcts, true_labels, video_uuids\n",
    "    term_freq = term_frequency_mat(codebook_lengh, wordids, wordcts)\n",
    "    return term_freq, true_labels, code_book, graphlets #online_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_labels = ['microwaving_food','openning_double_doors','printing_interface','printing_take_printout','take_from_fridge','take_paper_towel','take_tea_bag', 'throw_trash','use_kettle','use_water_cooler','washing_up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "for i in range(0,len(b)):\n",
    "    if b[i] == 'microwaving_food':\n",
    "        class_labels.append(0)\n",
    "    if b[i] == 'openning_double_doors':\n",
    "        class_labels.append(1)\n",
    "    if b[i] == 'printing_interface':\n",
    "        class_labels.append(2)\n",
    "    if b[i] == 'printing_take_printout':\n",
    "        class_labels.append(3)\n",
    "    if b[i] == 'take_from_fridge':\n",
    "        class_labels.append(4)\n",
    "    if b[i] == 'take_paper_towel':\n",
    "        class_labels.append(5)\n",
    "    if b[i] == 'take_tea_bag':\n",
    "        class_labels.append(6)\n",
    "    if b[i] == 'throw_trash':\n",
    "        class_labels.append(7)\n",
    "    if b[i] == 'use_kettle':\n",
    "        class_labels.append(8)\n",
    "    if b[i] == 'use_water_cooler':\n",
    "        class_labels.append(9)\n",
    "    if b[i] == 'washing_up':\n",
    "        class_labels.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def high_instance_code_words(term_frequency, code_book, graphlets, low_instance):\n",
    "    \"\"\"This essentially takes the feature space created over all events, and removes any\n",
    "    feature that is not witnessed in a minimum number of observations (low_instance param).\n",
    "    \"\"\"\n",
    "    ## Number of rows with non zero element :\n",
    "    keep_rows = np.where((term_frequency != 0).sum(axis=0) > low_instance)[0]   # removes code words if they dont appear in a minimum number of videos\n",
    "    # keep_rows = np.where(term_frequency.sum(axis=0) > low_instance)[0]        # removes code words if they dont appear a minimum number of times across all videos\n",
    "\n",
    "    ## Sum of the whole column: term_frequency.sum(axis=0) > low_instance\n",
    "    remove_inds = np.where((term_frequency != 0).sum(axis=0) <= low_instance)[0]\n",
    "\n",
    "    print(\"orig feature space: %s. remove: %s. new space: %s.\" % (len(term_frequency.sum(axis=0)), len(remove_inds), len(keep_rows)))\n",
    "\n",
    "    #keep only the columns of the feature space which have more than low_instance number of occurances.\n",
    "    selected_features = term_frequency.T[keep_rows]\n",
    "    new_term_frequency = selected_features.T\n",
    "    print(\"new feature space shape: \", new_term_frequency.shape)\n",
    "\n",
    "    # # Code Book (1d np array of hash values)\n",
    "    new_code_book = code_book[keep_rows]\n",
    "    print(\"  new code book len: \", len(new_code_book))\n",
    "\n",
    "    # # Graphlets book (1d np array of igraphs)\n",
    "    new_graphlets = graphlets[keep_rows]\n",
    "    print(\"  new graphlet book len: \", len(new_graphlets))\n",
    "\n",
    "    print(\"removed low (%s) instance graphlets\" % low_instance)\n",
    "    print(\"shape = \", new_term_frequency.shape)\n",
    "\n",
    "    return new_term_frequency, new_code_book, new_graphlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(tfreq, tlabels, cbook, glets) = load_term_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig feature space: 22829. remove: 12640. new space: 10189.\n",
      "new feature space shape:  (492, 10189)\n",
      "  new code book len:  10189\n",
      "  new graphlet book len:  10189\n",
      "removed low (1) instance graphlets\n",
      "shape =  (492, 10189)\n"
     ]
    }
   ],
   "source": [
    "(final_tfreq,final_cbook,final_glets) = high_instance_code_words(tfreq,cbook,glets,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_tfreq, class_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='linear', C=.1).fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9949109414758269\n"
     ]
    }
   ],
   "source": [
    "pred_train = classifier.predict(X_train)\n",
    "train_accuracy = 0\n",
    "for i in range(0,len(pred_train)):\n",
    "    if pred_train[i] == y_train[i]:\n",
    "        train_accuracy += 1\n",
    "train_accuracy = train_accuracy/len(pred_train)\n",
    "print('Train accuracy: ' + str(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797979797979798\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(0,len(predicted)):\n",
    "    if predicted[i] == y_test[i]:\n",
    "        accuracy += 1\n",
    "accuracy = accuracy/len(predicted)\n",
    "print('Test accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  7,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 11,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  6,  0,  3,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  8,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  4,  4,  0,  9,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  8,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0, 17]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773796709736\n",
      "0.773916944847\n",
      "0.77367651198\n",
      "1.73005097406\n",
      "0.773796719075\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "vscore = metrics.v_measure_score(y_test, predicted)\n",
    "hscore = metrics.homogeneity_score(y_test, predicted)\n",
    "cscore = metrics.completeness_score(y_test, predicted)\n",
    "mscore = metrics.mutual_info_score(y_test, predicted)\n",
    "nscore = metrics.normalized_mutual_info_score(y_test, predicted)\n",
    "\n",
    "print(vscore)\n",
    "print(hscore)\n",
    "print(cscore)\n",
    "print(mscore)\n",
    "print(nscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "8\n",
      "4\n",
      "12\n",
      "10\n",
      "9\n",
      "18\n",
      "9\n",
      "5\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#precision per class is the diagonal value for that row over the sum of rows\n",
    "precisions = []\n",
    "for i in range(0,11):\n",
    "    precisions.append(conf[i][i]/np.sum(conf[i][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of class microwaving_food is: 1.0\n",
      "Precision of class openning_double_doors is: 1.0\n",
      "Precision of class printing_interface is: 0.875\n",
      "Precision of class printing_take_printout is: 1.0\n",
      "Precision of class take_from_fridge is: 0.916666666667\n",
      "Precision of class take_paper_towel is: 0.6\n",
      "Precision of class take_tea_bag is: 0.888888888889\n",
      "Precision of class throw_trash is: 0.5\n",
      "Precision of class use_kettle is: 0.888888888889\n",
      "Precision of class use_water_cooler is: 0.6\n",
      "Precision of class washing_up is: 0.944444444444\n"
     ]
    }
   ],
   "source": [
    "for z in range(0,11):\n",
    "    print('Precision of class ' + text_labels[z] + ' is: ' + str(precisions[z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall per class is the diagonal value for that row over the sum of columns\n",
    "recalls = []\n",
    "sum_column = 0\n",
    "for i in range(0,11):\n",
    "    for j in range(0,11):\n",
    "        sum_column += conf[j][i]\n",
    "    recalls.append(conf[i][i]/sum_column)\n",
    "    sum_column=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of class microwaving_food is: 0.666666666667\n",
      "Recall of class openning_double_doors is: 1.0\n",
      "Recall of class printing_interface is: 1.0\n",
      "Recall of class printing_take_printout is: 0.8\n",
      "Recall of class take_from_fridge is: 0.6875\n",
      "Recall of class take_paper_towel is: 0.545454545455\n",
      "Recall of class take_tea_bag is: 1.0\n",
      "Recall of class throw_trash is: 0.692307692308\n",
      "Recall of class use_kettle is: 0.888888888889\n",
      "Recall of class use_water_cooler is: 1.0\n",
      "Recall of class washing_up is: 0.894736842105\n"
     ]
    }
   ],
   "source": [
    "for z in range(0,11):\n",
    "    print('Recall of class ' + text_labels[z] + ' is: ' + str(recalls[z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 value of class microwaving_food is: 0.8\n",
      "F1 value of class openning_double_doors is: 1.0\n",
      "F1 value of class printing_interface is: 0.933333333333\n",
      "F1 value of class printing_take_printout is: 0.888888888889\n",
      "F1 value of class take_from_fridge is: 0.785714285714\n",
      "F1 value of class take_paper_towel is: 0.571428571429\n",
      "F1 value of class take_tea_bag is: 0.941176470588\n",
      "F1 value of class throw_trash is: 0.58064516129\n",
      "F1 value of class use_kettle is: 0.888888888889\n",
      "F1 value of class use_water_cooler is: 0.75\n",
      "F1 value of class washing_up is: 0.918918918919\n"
     ]
    }
   ],
   "source": [
    "f_values = []\n",
    "for i in range(0,11):\n",
    "    f_values.append(2*precisions[i]*recalls[i]/(precisions[i]+recalls[i]))\n",
    "    print('F1 value of class ' + text_labels[i] + ' is: ' + str(f_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=11, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Wanted to attempt unsupervised clustering, similar to what others did. For some reason they used 10 clusters,\n",
    "but I think 11 make more sense because there are 11 activity classes.\n",
    "'''\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=11,init='k-means++')\n",
    "kmeans.fit(final_tfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2,  9,  9,  9,  2,  9,  0,  9,  9,  0,  9,  2,  3,  0,  9,  6,\n",
       "        2,  3,  2,  3,  9,  9,  6,  9,  2,  2,  3,  2,  0,  9,  0,  6,  0,\n",
       "        0,  9,  8,  5,  7,  9,  6,  4,  4,  9,  4,  5, 10,  4,  8,  6,  8,\n",
       "       10,  4,  9, 10,  7, 10,  8,  5,  7,  7, 10,  5,  7,  8,  5,  7, 10,\n",
       "        5,  5,  7,  4, 10,  7,  7,  7, 10,  5,  7,  4, 10,  8,  6, 10,  6,\n",
       "        7,  8, 10,  4,  4,  6,  8,  4,  4,  8, 10,  4,  4,  4,  5, 10,  7,\n",
       "       10,  4, 10, 10,  7, 10,  8,  6,  8,  4,  4,  5, 10,  6,  8,  5,  4,\n",
       "        4,  7,  6,  4,  4,  5,  7,  4, 10,  6,  4,  4,  7, 10, 10,  5,  7,\n",
       "        7,  4,  4,  7,  8,  7, 10,  4,  6,  8,  4,  2,  6,  4,  8,  4,  8,\n",
       "       10, 10,  6,  8,  4,  4,  7,  7, 10,  2, 10,  0, 10,  5, 10,  7,  8,\n",
       "        9,  0,  8, 10,  5,  7,  2, 10,  6,  8,  4,  4,  2,  3,  0,  2,  3,\n",
       "        4, 10,  7, 10,  8, 10,  2,  3,  0,  8, 10,  5,  9,  9,  2,  3,  2,\n",
       "        1,  3,  3, 10,  0,  9, 10,  5,  0,  7, 10,  7,  8,  5,  0,  9, 10,\n",
       "        5, 10,  7,  5,  7,  6,  8,  5,  7,  5,  7, 10, 10,  8,  6,  8,  4,\n",
       "        4,  8,  4,  6,  8,  4,  3,  2,  3,  1,  4,  7,  8,  8, 10,  1, 10,\n",
       "        2,  1,  3, 10, 10,  8,  5,  2,  3,  8,  6,  8,  4,  4,  0, 10,  5,\n",
       "        7,  4,  4, 10,  5,  7,  0, 10,  5,  7,  0, 10,  5,  7,  6,  4,  8,\n",
       "        9,  7,  8, 10,  8,  5, 10, 10,  8,  7,  5, 10,  5,  7,  7,  5,  7,\n",
       "        4, 10,  6,  8,  9, 10, 10,  5,  7,  1,  2,  3,  2,  3,  2,  2,  3,\n",
       "        1,  2,  3,  2,  3,  1,  1,  2,  3,  2,  2,  2,  2,  1,  2,  3,  3,\n",
       "        1,  3,  2,  3,  2,  1,  2,  7,  8,  4,  8, 10,  4, 10,  5,  7,  7,\n",
       "        8, 10,  6,  8,  4,  4,  9,  8,  7,  6,  8,  4,  4,  8,  4,  4,  8,\n",
       "        6,  8, 10,  4,  4,  8, 10,  7, 10,  8, 10,  5,  7,  6,  8,  4,  4,\n",
       "       10, 10, 10,  8, 10,  5,  7,  8,  8,  8,  5,  7,  5,  7,  6,  8,  4,\n",
       "        7,  4,  4, 10,  6, 10,  5, 10,  7, 10,  4,  4,  7,  5,  0,  7, 10,\n",
       "        4,  4,  5,  7,  8, 10,  5,  7,  4, 10,  6,  8,  4,  7,  4,  8, 10,\n",
       "        4, 10,  6,  8,  4,  4,  8,  4,  4, 10,  5,  6,  7, 10,  8, 10,  6,\n",
       "        8,  4,  7,  6,  8,  5,  7,  8,  6,  8,  4,  7,  8, 10,  5,  7,  5,\n",
       "        8, 10,  4,  4,  9,  8,  6,  8,  4,  4,  0,  7,  9,  8,  4,  4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples in class 0: 15\n",
      "[4, 4, 4, 4, 10, 4, 4, 0, 4, 7, 0, 4, 7, 10, 5]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 2\n",
      "The number of labels of 4 is 8\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 7 is 2\n",
      "The number of labels of 10 is 2\n",
      "\n",
      "Number of training examples in class 1: 9\n",
      "[4, 10, 10, 4, 10, 3, 4, 4, 5]\n",
      "Most common element is: 4\n",
      "The number of labels of 3 is 1\n",
      "The number of labels of 4 is 4\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 10 is 3\n",
      "\n",
      "Number of training examples in class 2: 27\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 7, 6, 7, 10, 7, 0, 4, 4, 9, 7, 7, 10, 4, 0, 7, 8, 4, 10, 7]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 2\n",
      "The number of labels of 4 is 12\n",
      "The number of labels of 6 is 1\n",
      "The number of labels of 7 is 7\n",
      "The number of labels of 8 is 1\n",
      "The number of labels of 9 is 1\n",
      "The number of labels of 10 is 3\n",
      "\n",
      "Number of training examples in class 3: 20\n",
      "[4, 4, 6, 4, 4, 4, 7, 2, 10, 8, 4, 1, 5, 4, 4, 4, 4, 10, 7, 10]\n",
      "Most common element is: 4\n",
      "The number of labels of 1 is 1\n",
      "The number of labels of 2 is 1\n",
      "The number of labels of 4 is 10\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 6 is 1\n",
      "The number of labels of 7 is 2\n",
      "The number of labels of 8 is 1\n",
      "The number of labels of 10 is 3\n",
      "\n",
      "Number of training examples in class 4: 69\n",
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 10, 0, 4, 6, 4, 4, 10, 4, 10, 7, 1, 4, 4, 10, 10, 4, 10, 4, 1, 10, 4, 3, 4, 10, 7, 4, 4, 10, 8, 4, 10, 7, 0, 7, 7, 4, 4, 4, 10, 10, 10, 10, 7, 7, 10, 4, 4, 5, 4, 4, 4, 4, 10, 8, 7, 1, 8, 4, 1]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 2\n",
      "The number of labels of 1 is 4\n",
      "The number of labels of 3 is 1\n",
      "The number of labels of 4 is 32\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 6 is 1\n",
      "The number of labels of 7 is 9\n",
      "The number of labels of 8 is 3\n",
      "The number of labels of 10 is 16\n",
      "\n",
      "Number of training examples in class 5: 35\n",
      "[4, 0, 10, 4, 4, 8, 4, 7, 4, 10, 4, 10, 0, 0, 7, 4, 4, 4, 0, 0, 4, 10, 7, 8, 10, 4, 1, 4, 4, 7, 10, 7, 0, 1, 7]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 6\n",
      "The number of labels of 1 is 2\n",
      "The number of labels of 4 is 13\n",
      "The number of labels of 7 is 6\n",
      "The number of labels of 8 is 2\n",
      "The number of labels of 10 is 6\n",
      "\n",
      "Number of training examples in class 6: 26\n",
      "[4, 1, 8, 10, 4, 7, 4, 10, 4, 4, 10, 7, 10, 7, 4, 8, 4, 4, 4, 5, 4, 3, 7, 4, 4, 4]\n",
      "Most common element is: 4\n",
      "The number of labels of 1 is 1\n",
      "The number of labels of 3 is 1\n",
      "The number of labels of 4 is 13\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 7 is 4\n",
      "The number of labels of 8 is 2\n",
      "The number of labels of 10 is 4\n",
      "\n",
      "Number of training examples in class 7: 47\n",
      "[4, 0, 0, 7, 4, 4, 0, 10, 4, 8, 4, 1, 10, 3, 4, 1, 4, 4, 4, 10, 4, 10, 7, 3, 4, 4, 4, 1, 4, 4, 4, 0, 4, 1, 4, 7, 4, 4, 7, 4, 8, 10, 4, 5, 4, 10, 4]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 4\n",
      "The number of labels of 1 is 4\n",
      "The number of labels of 3 is 2\n",
      "The number of labels of 4 is 24\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 7 is 4\n",
      "The number of labels of 8 is 2\n",
      "The number of labels of 10 is 6\n",
      "\n",
      "Number of training examples in class 8: 61\n",
      "[0, 0, 4, 4, 4, 4, 4, 10, 10, 10, 7, 10, 1, 4, 10, 7, 10, 4, 4, 4, 10, 1, 4, 4, 1, 4, 4, 10, 3, 4, 4, 10, 0, 10, 7, 4, 8, 4, 10, 0, 10, 10, 4, 8, 7, 7, 10, 10, 0, 5, 4, 4, 8, 4, 6, 10, 3, 10, 7, 7, 10]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 5\n",
      "The number of labels of 1 is 3\n",
      "The number of labels of 3 is 2\n",
      "The number of labels of 4 is 21\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 6 is 1\n",
      "The number of labels of 7 is 7\n",
      "The number of labels of 8 is 3\n",
      "The number of labels of 10 is 18\n",
      "\n",
      "Number of training examples in class 9: 21\n",
      "[4, 0, 4, 0, 4, 10, 10, 4, 7, 10, 10, 4, 4, 4, 10, 10, 4, 10, 4, 7, 1]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 2\n",
      "The number of labels of 1 is 1\n",
      "The number of labels of 4 is 9\n",
      "The number of labels of 7 is 2\n",
      "The number of labels of 10 is 7\n",
      "\n",
      "Number of training examples in class 10: 63\n",
      "[0, 4, 4, 0, 0, 1, 10, 4, 4, 4, 7, 10, 4, 4, 7, 1, 4, 4, 4, 7, 1, 4, 4, 7, 10, 4, 4, 4, 4, 8, 1, 8, 4, 10, 7, 3, 1, 7, 5, 7, 4, 4, 1, 1, 1, 0, 10, 6, 4, 10, 4, 4, 4, 4, 4, 4, 4, 8, 10, 8, 10, 8, 7]\n",
      "Most common element is: 4\n",
      "The number of labels of 0 is 4\n",
      "The number of labels of 1 is 8\n",
      "The number of labels of 3 is 1\n",
      "The number of labels of 4 is 27\n",
      "The number of labels of 5 is 1\n",
      "The number of labels of 6 is 1\n",
      "The number of labels of 7 is 8\n",
      "The number of labels of 8 is 5\n",
      "The number of labels of 10 is 8\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is my attempt to look at the break down of classes within each cluster, but it wasn't really a sucess because,\n",
    "as you can see in the results from this cell, a lot of the clusters have a majority of 5, and two only have 5. This\n",
    "ultimately makes it difficult to decipher the correct mapping when there aren't even unique cluster labels when\n",
    "taking the second most frequent of them all.\n",
    "'''\n",
    "\n",
    "kmeans_labels_0 = []\n",
    "kmeans_labels_1 = []\n",
    "kmeans_labels_2 = []\n",
    "kmeans_labels_3 = []\n",
    "kmeans_labels_4 = []\n",
    "kmeans_labels_5 = []\n",
    "kmeans_labels_6 = []\n",
    "kmeans_labels_7 = []\n",
    "kmeans_labels_8 = []\n",
    "kmeans_labels_9 = []\n",
    "kmeans_labels_10 = []\n",
    "\n",
    "def freq_of_label(lst):\n",
    "    for i in range(0,len(np.unique(lst))):\n",
    "        print('The number of labels of ' + str(np.unique(lst)[i]) + ' is ' + str(lst.count(np.unique(lst)[i])))\n",
    "        \n",
    "def most_common(lst):\n",
    "    return 'Most common element is: ' + str(max(set(lst), key=lst.count))\n",
    "\n",
    "for i in range(0,len(y_train)):\n",
    "    if y_train[i] == 0:\n",
    "        kmeans_labels_0.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 1:\n",
    "        kmeans_labels_1.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 2:\n",
    "        kmeans_labels_2.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 3:\n",
    "        kmeans_labels_3.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 4:\n",
    "        kmeans_labels_4.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 5:\n",
    "        kmeans_labels_5.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 6:\n",
    "        kmeans_labels_6.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 7:\n",
    "        kmeans_labels_7.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 8:\n",
    "        kmeans_labels_8.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 9:\n",
    "        kmeans_labels_9.append(kmeans.labels_[i])\n",
    "    if y_train[i] == 10:\n",
    "        kmeans_labels_10.append(kmeans.labels_[i])\n",
    "            \n",
    "\n",
    "num_0 = y_train.count(0)\n",
    "print('Number of training examples in class 0: ' + str(num_0))\n",
    "print(kmeans_labels_0)\n",
    "print(most_common(kmeans_labels_0))\n",
    "freq_of_label(kmeans_labels_0)\n",
    "\n",
    "print()\n",
    "num_1 = y_train.count(1)\n",
    "print('Number of training examples in class 1: ' + str(num_1))\n",
    "print(kmeans_labels_1)  \n",
    "print(most_common(kmeans_labels_1))\n",
    "freq_of_label(kmeans_labels_1)\n",
    "\n",
    "print()\n",
    "num_2 = y_train.count(2)\n",
    "print('Number of training examples in class 2: ' + str(num_2))\n",
    "print(kmeans_labels_2) \n",
    "print(most_common(kmeans_labels_2))\n",
    "freq_of_label(kmeans_labels_2)\n",
    "\n",
    "print()\n",
    "num_3 = y_train.count(3)\n",
    "print('Number of training examples in class 3: ' + str(num_3))\n",
    "print(kmeans_labels_3)   \n",
    "print(most_common(kmeans_labels_3))\n",
    "freq_of_label(kmeans_labels_3)\n",
    "\n",
    "print()\n",
    "num_4 = y_train.count(4)\n",
    "print('Number of training examples in class 4: ' + str(num_4))\n",
    "print(kmeans_labels_4) \n",
    "print(most_common(kmeans_labels_4))\n",
    "freq_of_label(kmeans_labels_4)\n",
    "\n",
    "print()\n",
    "num_5 = y_train.count(5)\n",
    "print('Number of training examples in class 5: ' + str(num_5))\n",
    "print(kmeans_labels_5) \n",
    "print(most_common(kmeans_labels_5))\n",
    "freq_of_label(kmeans_labels_5)\n",
    "\n",
    "print()\n",
    "num_6 = y_train.count(6)\n",
    "print('Number of training examples in class 6: ' + str(num_6))\n",
    "print(kmeans_labels_6)\n",
    "print(most_common(kmeans_labels_6))\n",
    "freq_of_label(kmeans_labels_6)\n",
    "\n",
    "print()\n",
    "num_7 = y_train.count(7)\n",
    "print('Number of training examples in class 7: ' + str(num_7))\n",
    "print(kmeans_labels_7) \n",
    "print(most_common(kmeans_labels_7))\n",
    "freq_of_label(kmeans_labels_7)\n",
    "\n",
    "print()\n",
    "num_8 = y_train.count(8)\n",
    "print('Number of training examples in class 8: ' + str(num_8))\n",
    "print(kmeans_labels_8) \n",
    "print(most_common(kmeans_labels_8))\n",
    "freq_of_label(kmeans_labels_8)\n",
    "\n",
    "print()\n",
    "num_9 = y_train.count(9)\n",
    "print('Number of training examples in class 9: ' + str(num_9))\n",
    "print(kmeans_labels_9)\n",
    "print(most_common(kmeans_labels_9))\n",
    "freq_of_label(kmeans_labels_9)\n",
    "\n",
    "print()\n",
    "num_10 = y_train.count(10)\n",
    "print('Number of training examples in class 10: ' + str(num_10))  \n",
    "print(kmeans_labels_10)   \n",
    "print(most_common(kmeans_labels_10))\n",
    "freq_of_label(kmeans_labels_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414145808575\n",
      "0.369038243286\n",
      "0.471815891616\n",
      "0.829242253373\n",
      "0.417274619162\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "'''\n",
    "these are five different evaluation metrics typically used for k-means or unsupervised learning paradigms\n",
    "v_measure score is supposed to be the same as the normalized mutual info score but they're slightly different-\n",
    "not sure why. v measure/normalized mutual info score is the measure of similarity between the two labels of the same\n",
    "data, but normalized to be between 0 and 1, with 1 being a perfect correlation adn 0 being no mutual information.\n",
    "mutual_info_score is just not normalized yet.\n",
    "\n",
    "Homogeneity: if all of its clusters contain only data points which are members of a single class\n",
    "Completeness: if all the data points that are members of a given class are elements of the same cluster\n",
    "\n",
    "'''\n",
    "vscore = metrics.v_measure_score(class_labels, pred_labels)\n",
    "hscore = metrics.homogeneity_score(class_labels, pred_labels)\n",
    "cscore = metrics.completeness_score(class_labels, pred_labels)\n",
    "mscore = metrics.mutual_info_score(class_labels, pred_labels)\n",
    "nscore = metrics.normalized_mutual_info_score(class_labels, pred_labels)\n",
    "\n",
    "print(vscore)\n",
    "print(hscore)\n",
    "print(cscore)\n",
    "print(mscore)\n",
    "print(nscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7,  7,  6,  7,  2,  9,  5,  5,  1,  9, 10,  4,  7,  8,  7,  4,\n",
       "        4,  7,  7, 10,  0, 10,  0,  5,  7,  5, 10,  4,  5,  6,  8,  4,  7,\n",
       "        0,  2,  2,  9, 10,  5,  2,  8, 10, 10,  6,  5,  3,  7, 10,  8,  5,\n",
       "        6,  6,  9,  8,  6,  6, 10,  7,  6, 10,  7,  8,  4,  2,  5, 10,  7,\n",
       "        8,  4, 10,  2,  1,  8,  4, 10,  5,  4,  3, 10,  7,  7,  7,  3,  6,\n",
       "        4,  3,  8,  7, 10,  9,  4, 10,  2,  2,  4, 10, 10,  0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.77555756e-17,  -2.22044605e-16,  -1.11022302e-16, ...,\n",
       "         -1.73472348e-18,  -1.73472348e-18,  -1.73472348e-18],\n",
       "       [  4.00000000e-02,   8.00000000e-02,   4.00000000e-02, ...,\n",
       "         -1.73472348e-18,  -1.73472348e-18,  -1.73472348e-18],\n",
       "       [  2.77555756e-17,   0.00000000e+00,  -5.55111512e-17, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  2.77555756e-17,   1.25000000e-01,  -5.55111512e-17, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  2.77555756e-17,   0.00000000e+00,  -5.55111512e-17, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  2.14285714e-01,   2.92857143e+00,   2.85714286e-01, ...,\n",
       "         -1.73472348e-18,  -1.73472348e-18,  -1.73472348e-18]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just wanted to take a look at what the centers are like\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=None, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=1, seeds=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "I'm now going to try MeanShift clustering because it doesn't necessarily assign all data points to a cluster,\n",
    "and doesn't ask for a specific number of clusters as input. I think this data is probably pretty noisy \n",
    "based off the results with kmeans, so I'd like to see how different the results end up being\n",
    "'''\n",
    "from sklearn.cluster import MeanShift\n",
    "mean_cluster = MeanShift()\n",
    "mean_cluster.fit(final_tfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_labels = mean_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22257772949\n",
      "0.171868799082\n",
      "0.31573298559\n",
      "0.386195395268\n",
      "0.232947738911\n"
     ]
    }
   ],
   "source": [
    "mc_vscore = metrics.v_measure_score(class_labels, mc_labels)\n",
    "mc_hscore = metrics.homogeneity_score(class_labels, mc_labels)\n",
    "mc_cscore = metrics.completeness_score(class_labels, mc_labels)\n",
    "mc_mscore = metrics.mutual_info_score(class_labels, mc_labels)\n",
    "mc_nscore = metrics.normalized_mutual_info_score(class_labels, mc_labels)\n",
    "\n",
    "print(mc_vscore)\n",
    "print(mc_hscore)\n",
    "print(mc_cscore)\n",
    "print(mc_mscore)\n",
    "print(mc_nscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48200689336\n",
      "0.583819239325\n",
      "0.410431642691\n",
      "1.31186290415\n",
      "0.489507803238\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "It appears that meanshift actually performs significantly worse because it just doens't account for\n",
    "a lot of the noise, and a large amount of the data is noisy so this actually doesn't help. I'll try affinity \n",
    "propagation clustering below which does account for the noise and assigns each data point to a cluster.\n",
    "'''\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "af_cluster = AffinityPropagation()\n",
    "af_cluster.fit(final_tfreq)\n",
    "af_labels = af_cluster.labels_\n",
    "\n",
    "af_vscore = metrics.v_measure_score(class_labels, af_labels)\n",
    "af_hscore = metrics.homogeneity_score(class_labels, af_labels)\n",
    "af_cscore = metrics.completeness_score(class_labels, af_labels)\n",
    "af_mscore = metrics.mutual_info_score(class_labels, af_labels)\n",
    "af_nscore = metrics.normalized_mutual_info_score(class_labels, af_labels)\n",
    "\n",
    "print(af_vscore)\n",
    "print(af_hscore)\n",
    "print(af_cscore)\n",
    "print(af_mscore)\n",
    "print(af_nscore)\n",
    "#seems to do a much better job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 48,  8,  1,  1, 47,  8,  1,  8,  8,  1,  1,  8, 48,  2,  8,  8,\n",
       "        8, 48, 48,  8,  8,  3,  8, 58, 48,  4,  8,  8,  1,  8,  1, 14,  1,\n",
       "        1,  8,  5,  6, 15,  1, 58, 15,  6,  8,  8,  6, 46,  7, 46, 58,  8,\n",
       "        8,  6,  9, 46,  6, 10, 46,  6, 15,  6,  8,  6, 15,  8,  8,  6,  8,\n",
       "        6,  8,  6,  6,  8, 57, 15, 15, 11, 15,  6, 17, 12,  8, 58, 13, 14,\n",
       "       77, 74,  8, 15, 15, 14,  8, 15, 15,  8, 46, 16, 17,  6,  6, 18, 74,\n",
       "        8, 57,  8, 19, 15, 46, 43, 14, 74, 15,  6,  6, 46, 58,  6,  8, 33,\n",
       "        8, 15,  8, 15, 15,  6, 15, 15,  8, 58,  6,  6,  6, 46,  8,  6, 15,\n",
       "        6, 15, 15,  6, 63, 57, 46,  6, 58, 33,  8,  8, 58, 20, 43, 21, 33,\n",
       "       33, 46, 58, 63, 57, 22,  8, 57, 46, 25,  8,  8,  8,  6, 23,  8, 63,\n",
       "       24, 24, 46, 46,  6,  6, 25, 46, 58, 46, 15, 45, 48, 48,  2, 25, 48,\n",
       "        6,  8, 15, 46, 43, 26, 47, 48, 27,  8, 28, 46,  8, 29,  8, 48,  8,\n",
       "        8,  8, 48, 46,  1,  1, 30, 45,  2,  6, 58, 15, 63, 31,  1,  1, 46,\n",
       "       15,  8,  6, 15, 15, 14, 32,  6,  6,  6,  6, 33, 34, 33, 58, 33, 33,\n",
       "       33, 33, 74,  8,  8, 35,  8, 36, 48, 48, 37, 45, 43, 63, 33, 48, 38,\n",
       "        8, 48, 48,  8,  8, 63, 15,  8, 48, 63, 58,  6, 17, 15,  1, 46, 15,\n",
       "       15, 15,  6, 46, 15, 15,  1, 39, 58, 58, 40,  8, 41, 17, 73, 42, 43,\n",
       "        1, 15,  8, 61, 33, 15, 38, 44, 63,  6,  6, 33, 15,  6, 15, 45,  8,\n",
       "        6, 46, 58, 33,  1, 46, 46, 15,  6,  8, 47, 48, 47, 48, 49, 50, 48,\n",
       "        8, 51,  8, 52, 48,  8,  8, 47,  8,  8, 53, 54, 47,  8, 55, 48, 48,\n",
       "        8,  8, 48,  8,  8,  8, 47, 17, 63,  6,  6, 61, 15, 56, 45, 15, 57,\n",
       "        6, 46, 58, 74, 72, 57, 14, 63, 57, 73, 59, 57, 15, 66, 60, 45, 43,\n",
       "       58, 63, 61, 17, 15,  8, 61, 17, 61,  6,  8, 15, 15, 58,  8, 17,  6,\n",
       "       46, 62, 61, 63,  8,  6, 15,  8, 63, 33,  6,  6,  6, 57, 14, 33,  6,\n",
       "       57, 57, 15, 64, 65, 46, 33, 61, 57, 46, 57,  6, 57, 15,  8, 57,  8,\n",
       "       57, 45,  6,  6, 66, 67, 45, 15, 72,  8, 68, 69, 17, 57, 17, 63, 33,\n",
       "       70, 71, 58, 43, 45, 72, 43, 15,  6, 33, 15, 58, 15, 33,  8, 46, 58,\n",
       "       63, 72, 17, 73, 77,  6,  8, 74, 58,  6, 75, 17, 77, 33, 15, 15, 15,\n",
       "       63, 61, 45, 17, 76, 77, 46, 77, 22, 22,  1, 15, 76, 63, 45,  6])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
